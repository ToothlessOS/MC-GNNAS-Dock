{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689f4d0b",
   "metadata": {},
   "source": [
    "# Analyze the results of the 10-fold test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c6f17",
   "metadata": {},
   "source": [
    "## Performance by algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a5bf9",
   "metadata": {},
   "source": [
    "## Warning!!! Delete all temp_*.txt csv files before rerunning test_kfold.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the temp.csv file, which is generated automatically after each 10-fold test run with test_kfold.sh\n",
    "# WARNING: Please delete the current temp.csv file each time before running a new 10-fold test\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by algorithm\n",
    "columns = ['surf', 'uni', 'gnina', 'smina', 'qvina', 'diff', 'diffL', 'karma']\n",
    "perf_by_algo = dict()\n",
    "\n",
    "print(\"Performance by algorithm:\")\n",
    "\n",
    "# Extract and store data\n",
    "for algo in columns:\n",
    "    if f'{algo}_rmsd_lt_1_valid' in data.columns and f'{algo}_rmsd_lt_2_valid' in data.columns:\n",
    "        algo_percent_rmsd_lt_1_valid = data[f'{algo}_rmsd_lt_1_valid'].values\n",
    "        algo_percent_rmsd_lt_2_valid = data[f'{algo}_rmsd_lt_2_valid'].values\n",
    "        perf_by_algo[algo] = {\n",
    "            \"RMSD < 1 & PB-Valid\": algo_percent_rmsd_lt_1_valid,\n",
    "            \"RMSD < 2 & PB-Valid\": algo_percent_rmsd_lt_2_valid\n",
    "        }\n",
    "\n",
    "perf_by_algo[\"AS\"] = {\n",
    "    \"RMSD < 1 & PB-Valid\": data[\"AS_rmsd_lt_1_valid\"].values,\n",
    "    \"RMSD < 2 & PB-Valid\": data[\"AS_rmsd_lt_2_valid\"].values\n",
    "}\n",
    "\n",
    "# Results graph\n",
    "# Prepare data for plotting\n",
    "algorithms = list(perf_by_algo.keys())\n",
    "rmsd_lt_1_means = [perf_by_algo[algo][\"RMSD < 1 & PB-Valid\"].mean() for algo in algorithms]\n",
    "rmsd_lt_2_means = [perf_by_algo[algo][\"RMSD < 2 & PB-Valid\"].mean() for algo in algorithms]\n",
    "rmsd_lt_1_stds = [perf_by_algo[algo][\"RMSD < 1 & PB-Valid\"].std() for algo in algorithms]\n",
    "rmsd_lt_2_stds = [perf_by_algo[algo][\"RMSD < 2 & PB-Valid\"].std() for algo in algorithms]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars\n",
    "bars1 = ax.bar(x - width/2, rmsd_lt_1_means, width, label='RMSD < 1 & PB-Valid', \n",
    "               yerr=rmsd_lt_1_stds, capsize=5, alpha=0.8, color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, rmsd_lt_2_means, width, label='RMSD < 2 & PB-Valid',\n",
    "               yerr=rmsd_lt_2_stds, capsize=5, alpha=0.8, color='lightcoral')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Success Rate (%)', fontsize=12)\n",
    "ax.set_title('Algorithm Performance Comparison (10-Fold Cross-Validation)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithms, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3),  # 3 points vertical offset\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(f\"Best performing algorithm (RMSD < 1): {algorithms[np.argmax(rmsd_lt_1_means)]} ({max(rmsd_lt_1_means):.2f}%)\")\n",
    "print(f\"Best performing algorithm (RMSD < 2): {algorithms[np.argmax(rmsd_lt_2_means)]} ({max(rmsd_lt_2_means):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538319f5",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a235b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Wilcoxon p-test for results\n",
    "# Is the performance gain with AS significant?\n",
    "# Define algorithms and metrics\n",
    "algorithms = ['surf', 'uni', 'gnina', 'smina', 'qvina', 'diff', 'diffL', 'karma']\n",
    "metrics = ['rmsd_lt_1_valid_gain', 'rmsd_lt_2_valid_gain']\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WILCOXON SIGNED-RANK TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "    \n",
    "for algo in algorithms:\n",
    "    print(f\"\\n--- {algo.upper()} ---\")\n",
    "        \n",
    "    for metric in metrics:\n",
    "        col_name = f\"{algo}_{metric}\"\n",
    "            \n",
    "        if col_name in data.columns:\n",
    "            gain_values = data[col_name].values\n",
    "                \n",
    "            # Remove NaN values if any\n",
    "            gain_values = gain_values[~np.isnan(gain_values)]\n",
    "                \n",
    "            if len(gain_values) > 0:\n",
    "                # Perform Wilcoxon signed-rank test\n",
    "                try:\n",
    "                    w_stat, w_p = stats.wilcoxon(gain_values, alternative='greater')\n",
    "                        \n",
    "                    # Calculate summary statistics\n",
    "                    mean_gain = np.mean(gain_values)\n",
    "                    median_gain = np.median(gain_values)\n",
    "                    positive_gains = np.sum(gain_values > 0)\n",
    "                    negative_gains = np.sum(gain_values < 0)\n",
    "                    zero_gains = np.sum(gain_values == 0)\n",
    "                    total_cases = len(gain_values)\n",
    "                        \n",
    "                    print(f\"  {metric.replace('_', ' ').title()}:\")\n",
    "                    print(f\"    Mean gain: {mean_gain:.3f}\")\n",
    "                    print(f\"    Median gain: {median_gain:.3f}\")\n",
    "                    print(f\"    Positive gains: {positive_gains}/{total_cases} ({100*positive_gains/total_cases:.1f}%)\")\n",
    "                    print(f\"    Negative gains: {negative_gains}/{total_cases} ({100*negative_gains/total_cases:.1f}%)\")\n",
    "                    print(f\"    Zero gains: {zero_gains}/{total_cases} ({100*zero_gains/total_cases:.1f}%)\")\n",
    "                    print(f\"    Wilcoxon statistic: {w_stat:.4f}\")\n",
    "                    print(f\"    P-value: {w_p:.6f}\")\n",
    "                        \n",
    "                    # Significance indicator\n",
    "                    if w_p < 0.001:\n",
    "                        sig_level = \"***\"\n",
    "                    elif w_p < 0.01:\n",
    "                        sig_level = \"**\"\n",
    "                    elif w_p < 0.05:\n",
    "                        sig_level = \"*\"\n",
    "                    else:\n",
    "                        sig_level = \"\"\n",
    "                        \n",
    "                    print(f\"    Significance: {sig_level}\")\n",
    "                        \n",
    "                except ValueError as e:\n",
    "                    print(f\"  {metric.replace('_', ' ').title()}: Cannot perform test - {str(e)}\")\n",
    "            else:\n",
    "                print(f\"  {metric.replace('_', ' ').title()}: No valid data points\")\n",
    "        else:\n",
    "            print(f\"  {metric.replace('_', ' ').title()}: Column not found\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEGEND: *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f261d",
   "metadata": {},
   "source": [
    "## Algorithm selection portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980346c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the temp_portfolio.csv file, which is generated automatically after each 10-fold test run with test_kfold.sh\n",
    "# WARNING: Please delete the current temp_portfolio.csv file each time before running a new 10-fold test\n",
    "data_portfolio = pd.read_csv(\"../temp_portfolio.csv\")\n",
    "algorithm_counts = data_portfolio['selected_algorithm'].value_counts()\n",
    "print(algorithm_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_AS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
