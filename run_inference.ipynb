{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3e7f96",
   "metadata": {},
   "source": [
    "# Sample inference pipeline (& runtime evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1db4cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required dependencies\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning.callbacks as plc\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "## Graph generation dependencies\n",
    "from create_graph.Ligand_graph import construct_ligand_graph, convert_to_pyg\n",
    "from create_graph.Protein_graph import parallel_process_proteins\n",
    "\n",
    "## Model dependecies\n",
    "from model import MInterface\n",
    "from data import DInterface\n",
    "from utils import load_model_path_by_args, plot_rmsd_metrics\n",
    "\n",
    "from data.dataset import prepare_data_binary, prepare_data_point, prepare_data_pose, prepare_data_rmsd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import stats\n",
    "\n",
    "from utils import ndcg_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed864c",
   "metadata": {},
   "source": [
    "## Prepare the graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044ea34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset/raw_inference\"\n",
    "save_dir_protein = \"dataset/protein_g_inference\"\n",
    "save_dir_ligand = \"dataset/ligand_g_inference\"\n",
    "\n",
    "# Generate the index for protein/ligand pairs\n",
    "index = os.listdir(path)\n",
    "print(len(index)) # Datapoint count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 100 proteins with 1 workers\n",
      "ESM processing will be serialized to prevent CUDA memory conflicts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bd377ff510402a9e6f972ddb8c09ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677e12a6dc6a413180700e480432e0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM processing failed for task 1b0p_TPP_B_1236_A_135898603714240: CUDA out of memory. Tried to allocate 3.74 GiB. GPU 0 has a total capacity of 7.62 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 6.45 GiB memory in use. Of the allocated memory 6.26 GiB is allocated by PyTorch, and 78.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Failed to process 1b0p_TPP_B_1236: ESM processing failed for task 1b0p_TPP_B_1236_A_135898603714240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7674c477f90048798e931bbba0c20ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1amr_PMP_A_413_A_135898603714240: GPU memory before: 2.52GB, after: 2.90GB\n",
      "Successfully processed 1amr_PMP_A_413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f966d8b700c43a1b15de6b809923116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1awb_IPD_A_281_A_135898603714240: GPU memory before: 2.90GB, after: 2.69GB\n",
      "ESM task 1awb_IPD_A_281_B_135898603714240: GPU memory before: 2.69GB, after: 2.69GB\n",
      "Successfully processed 1awb_IPD_A_281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1b3d_S27_B_401_A_135898603714240: GPU memory before: 2.69GB, after: 2.58GB\n",
      "ESM task 1b3d_S27_B_401_B_135898603714240: GPU memory before: 2.58GB, after: 2.58GB\n",
      "Successfully processed 1b3d_S27_B_401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6068eaa8b5364d9ebcc4fcf6f9683d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1ajs_PLA_A_415_A_135898603714240: GPU memory before: 2.58GB, after: 2.93GB\n",
      "ESM task 1ajs_PLA_A_415_B_135898603714240: GPU memory before: 2.93GB, after: 2.93GB\n",
      "Successfully processed 1ajs_PLA_A_415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb7934413a6400195f902ffa8f7246f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1a49_ATP_C_1735_A_135898603714240: GPU memory before: 2.93GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_B_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_C_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_D_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_E_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_F_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "ESM task 1a49_ATP_C_1735_G_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6edab8aab1406097df93b637ecfdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1a49_ATP_C_1735_H_135898603714240: GPU memory before: 3.21GB, after: 3.21GB\n",
      "Successfully processed 1a49_ATP_C_1735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa0adb311f64a17855658d3b386a9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM processing failed for task 1ami_MIC_A_755_A_135898603714240: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 7.62 GiB of which 1.36 GiB is free. Including non-PyTorch memory, this process has 6.24 GiB memory in use. Of the allocated memory 6.04 GiB is allocated by PyTorch, and 92.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Failed to process 1ami_MIC_A_755: ESM processing failed for task 1ami_MIC_A_755_A_135898603714240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aex_THP_A_151_A_135898603714240: GPU memory before: 3.21GB, after: 2.56GB\n",
      "Successfully processed 1aex_THP_A_151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ad4f2db1cf4b4ebea97b270d0672ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aqx_GTD_B_2201_A_135898603714240: GPU memory before: 2.56GB, after: 2.61GB\n",
      "ESM task 1aqx_GTD_B_2201_B_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n",
      "ESM task 1aqx_GTD_B_2201_C_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0790338626d1454da78baed6797b9dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aqx_GTD_B_2201_D_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n",
      "Successfully processed 1aqx_GTD_B_2201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2964c8aed9a452db2a8043acd8d309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1a5w_Y3_A_1_A_135898603714240: GPU memory before: 2.61GB, after: 2.56GB\n",
      "Successfully processed 1a5w_Y3_A_1\n",
      "Completed 10/100 proteins. GPU memory: 2.56GB allocated, 2.65GB reserved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aqx_GTD_C_2301_A_135898603714240: GPU memory before: 2.56GB, after: 2.61GB\n",
      "ESM task 1aqx_GTD_C_2301_B_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n",
      "ESM task 1aqx_GTD_C_2301_C_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30bf5367b594332aecd303df7f94225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aqx_GTD_C_2301_D_135898603714240: GPU memory before: 2.61GB, after: 2.61GB\n",
      "Successfully processed 1aqx_GTD_C_2301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aog_MAE_A_500_A_135898603714240: GPU memory before: 2.61GB, after: 3.09GB\n",
      "ESM task 1aog_MAE_A_500_B_135898603714240: GPU memory before: 3.09GB, after: 3.09GB\n",
      "Successfully processed 1aog_MAE_A_500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038a4f75d8c8438a8998fea0cde35d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM processing failed for task 1b0p_TPP_A_1236_A_135898603714240: CUDA out of memory. Tried to allocate 3.74 GiB. GPU 0 has a total capacity of 7.62 GiB of which 559.19 MiB is free. Including non-PyTorch memory, this process has 7.05 GiB memory in use. Of the allocated memory 6.85 GiB is allocated by PyTorch, and 96.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Failed to process 1b0p_TPP_A_1236: ESM processing failed for task 1b0p_TPP_A_1236_A_135898603714240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d993fa01e1e24980b604de21282d7aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e58cfbf86014b5292b2cbf3c94f6ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1amq_PMP_A_413_A_135898603714240: GPU memory before: 3.10GB, after: 2.90GB\n",
      "Successfully processed 1amq_PMP_A_413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM task 1aj2_2PH_A_283_A_135898603714240: GPU memory before: 2.90GB, after: 2.70GB\n",
      "Successfully processed 1aj2_2PH_A_283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261010cf2be54ec6b75c7c30f2435e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Protein graph\n",
    "## Configuration for protein graph construction\n",
    "from graphein.protein.config import ProteinGraphConfig\n",
    "from graphein.protein.features.nodes.amino_acid import amino_acid_one_hot\n",
    "from graphein.protein.edges.distance import (\n",
    "    add_peptide_bonds,\n",
    "    add_hydrogen_bond_interactions,\n",
    "    add_disulfide_interactions,\n",
    "    add_ionic_interactions,\n",
    "    add_aromatic_interactions,\n",
    "    add_aromatic_sulphur_interactions,\n",
    "    add_cation_pi_interactions\n",
    ")\n",
    "\n",
    "config = ProteinGraphConfig(\n",
    "    granularity=\"centroids\",\n",
    "    node_metadata_functions=[amino_acid_one_hot],\n",
    "    edge_construction_functions=[\n",
    "        add_peptide_bonds,\n",
    "        add_aromatic_interactions,\n",
    "        add_hydrogen_bond_interactions,\n",
    "        add_disulfide_interactions,\n",
    "        add_ionic_interactions,\n",
    "        add_aromatic_sulphur_interactions,\n",
    "        add_cation_pi_interactions,\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Construct the protein graph\n",
    "parallel_process_proteins(index, config, save_dir_protein, num_workers=1, chunk_size=100, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1b0p_TPP_B_1236 saved\n",
      "1amr_PMP_A_413 saved\n",
      "1awb_IPD_A_281 saved\n",
      "1b3d_S27_B_401 saved\n",
      "1ajs_PLA_A_415 saved\n",
      "1a49_ATP_C_1735 saved\n",
      "1ami_MIC_A_755 saved\n",
      "1aex_THP_A_151 saved\n",
      "1aqx_GTD_B_2201 saved\n",
      "1a5w_Y3_A_1 saved\n",
      "1aqx_GTD_C_2301 saved\n",
      "1aog_MAE_A_500 saved\n",
      "1b0p_TPP_A_1236 saved\n",
      "1amq_PMP_A_413 saved\n",
      "1aj2_2PH_A_283 saved\n",
      "1a49_ATP_D_2335 saved\n",
      "1a3u_THP_A_151 saved\n",
      "1a80_NDP_A_300 saved\n",
      "1aog_FAD_A_492 saved\n",
      "1aer_TIA_B_700 saved\n",
      "1a49_OXL_F_4133 saved\n",
      "1afq_0FG_B_304 saved\n",
      "1aej_NVI_A_296 saved\n",
      "1akd_CAM_A_420 saved\n",
      "1axd_GGL_C_1 saved\n",
      "1aiq_CB3_B_267 saved\n",
      "1ac4_TMT_A_296 saved\n",
      "1a0g_PMP_A_285 saved\n",
      "1aiq_UMP_B_266 saved\n",
      "1a96_PCP_B_301 saved\n",
      "1afe_ASP_I_55 saved\n",
      "1a49_OXL_H_5333 saved\n",
      "1aog_FAD_B_492 saved\n",
      "1a59_COA_A_380 saved\n",
      "1anc_BEN_A_290 saved\n",
      "1abn_NDP_A_351 saved\n",
      "1ah4_NAP_A_318 saved\n",
      "1a59_CIT_A_379 saved\n",
      "1b7y_FYA_A_1002 saved\n",
      "1axg_NAD_C_403 saved\n",
      "1af7_SAH_A_287 saved\n",
      "1a96_PCP_C_302 saved\n",
      "1a0g_PMP_B_285 saved\n",
      "1aer_TAD_A_700 saved\n",
      "1aia_PMP_A_411 saved\n",
      "1a49_OXL_E_3533 saved\n",
      "1aj8_CIT_A_1000 saved\n",
      "1a4i_NDP_A_302 saved\n",
      "1a96_XAN_C_303 saved\n",
      "1a8u_BEZ_B_294 saved\n",
      "1a5x_Y3_A_1 saved\n",
      "1amu_AMP_B_567 saved\n",
      "1aqx_GTD_D_2401 saved\n",
      "1aqx_GTD_A_2101 saved\n",
      "1aer_AMP_B_701 saved\n",
      "1a49_OXL_A_533 saved\n",
      "1axg_NAD_D_403 saved\n",
      "1a49_OXL_B_1133 saved\n",
      "1b4v_FAD_A_510 saved\n",
      "1a96_XAN_B_304 saved\n",
      "1afe_ALZ_H_600 saved\n",
      "1b7t_ADP_A_999 saved\n",
      "1a49_OXL_C_1733 saved\n",
      "1a49_ATP_E_3535 saved\n",
      "1aj8_COA_B_4000 saved\n",
      "1aiq_UMP_A_265 saved\n",
      "1axg_ETF_B_404 saved\n",
      "1amu_AMP_A_567 saved\n",
      "1axg_NAD_B_403 saved\n",
      "1axg_ETF_D_404 saved\n",
      "1amr_MAE_A_414 saved\n",
      "1ah0_SBI_A_320 saved\n",
      "1axg_NAD_A_403 saved\n",
      "1ads_NAP_A_350 saved\n",
      "1aia_PMP_B_411 saved\n",
      "1axd_GGL_D_1 saved\n",
      "1a49_OXL_G_4733 saved\n",
      "1axg_ETF_C_404 saved\n",
      "1aua_BOG_A_1 saved\n",
      "1aog_MAE_A_501 saved\n",
      "1a49_ATP_A_535 saved\n",
      "1a49_ATP_F_4135 saved\n",
      "1a49_ATP_G_4735 saved\n",
      "1anc_BEN_A_384 saved\n",
      "1a7x_FKA_B_201 saved\n",
      "1axg_ETF_A_404 saved\n",
      "1aef_3AP_A_296 saved\n",
      "1a4i_NDP_B_302 saved\n",
      "1b9z_GLC_B_1 saved\n",
      "1a49_OXL_D_2333 saved\n",
      "1a8u_BEZ_A_295 saved\n",
      "1afq_0FG_C_301 saved\n",
      "1aiq_CB3_A_266 saved\n",
      "1a9r_HPA_A_290 saved\n",
      "1aj8_COA_A_3000 saved\n",
      "1apu_32L_I_1 saved\n",
      "1ah0_NAP_A_318 saved\n",
      "1aj8_CIT_B_2000 saved\n",
      "1awb_IPD_B_1 saved\n",
      "1aua_BOG_A_2 saved\n"
     ]
    }
   ],
   "source": [
    "# Ligand graph generation\n",
    "## Configuration for ligand graph construction\n",
    "import graphein.molecule as gm\n",
    "from functools import partial\n",
    "\n",
    "config = gm.MoleculeGraphConfig(\n",
    "    node_metadata_functions=[\n",
    "        gm.atom_type_one_hot,\n",
    "        gm.atomic_mass,\n",
    "        gm.degree,\n",
    "        gm.total_degree,\n",
    "        gm.total_valence,\n",
    "        gm.explicit_valence,\n",
    "        gm.implicit_valence,\n",
    "        gm.num_explicit_h,\n",
    "        gm.num_implicit_h,\n",
    "        gm.total_num_h,\n",
    "        gm.num_radical_electrons,\n",
    "        gm.formal_charge,\n",
    "        gm.is_aromatic,\n",
    "        gm.is_isotope,\n",
    "        gm.is_ring,\n",
    "        partial(gm.is_ring_size, ring_size=5),\n",
    "        partial(gm.is_ring_size, ring_size=7)\n",
    "    ]\n",
    ")\n",
    "\n",
    "proteins = pd.Series(index)\n",
    "graphs = proteins.apply(lambda p: construct_ligand_graph(p, path))\n",
    "# Convert all graphs\n",
    "pyg_graphs = [convert_to_pyg(g) for g in graphs]\n",
    "# Assuming pyg_graphs is a list containing your graph data objects\n",
    "proteins = proteins.to_list()\n",
    "os.makedirs(save_dir_ligand, exist_ok=True)\n",
    "for idx, pyg_graph in enumerate(pyg_graphs):\n",
    "    protein_name = proteins[idx]\n",
    "    file_name = f\"{save_dir_ligand}/pyg_graph_{protein_name}.pt\"\n",
    "    torch.save(pyg_graph, file_name)\n",
    "    print(f'{protein_name} saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662a5fd",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the data modules and add a `inference` function in main.py to handle this feature!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_AS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
